# 导库
from sklearn import tree
import pandas as pd
from sklearn.datasets import load_wine

from sklearn.model_selection import train_test_split

# 红酒数据集
wine=load_wine()
wine.data.shape

# 分类类型
wine.target
Xtrain,Xtest,Ytrain,Ytest=train_test_split(wine.data,wine.target,test_size=0.3)
Xtrain.shape

clf=tree.DecisionTreeClassifier(criterion='gini',random_state=2)
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest) #返回预测准确度
score

feature_name=wine.feature_names
import graphviz
dot_data=tree.export_graphviz(clf
                             ,out_file=None
                             ,feature_names=feature_name
                             ,class_names=['gin','sherry','belmode']
                             ,filled=True
                             ,rounded=True)
graph=graphviz.Source(dot_data)
graph

clf.feature_importances_

[*zip(feature_name,clf.feature_importances_)]

data=clf.feature_importances_
import matplotlib.pyplot as plt
plt.barh([1,2,3,4,5,6,7,8,9,10,11,12,13],data,tick_label=feature_name)
plt.show()

clf=tree.DecisionTreeClassifier(criterion='gini'
                               ,random_state=30
                               ,splitter='best') #best
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
score

#best用分枝时用更加重要的特征来分枝

# random 选取树枝，防止过拟合
clf=tree.DecisionTreeClassifier(criterion='gini'
                               ,random_state=30
                               ,splitter='random') 
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
score

#random在分枝时候更加随机，防止过拟合用。

import matplotlib.pyplot as plt
test=[]
for i in range(10):
    clf=tree.DecisionTreeClassifier(max_depth=i+1
                                   ,criterion='gini'
                                   ,random_state=30
                                )
    clf=clf.fit(Xtrain,Ytrain)
    score=clf.score(Xtest,Ytest)
    test.append(score)
    
plt.plot(range(1,11),test,color='r',label='max_depth')
plt.legend()
plt.show()

#leaf限定一个节点分枝后每个子节点都至少包含leaf个样本。否则不发生
#设置太小容易过拟合。太大就阻止模型学习了 一般从=5开始看。

test=[]
for i in range(1,11):
    clf=tree.DecisionTreeClassifier(max_depth=3,
                                   criterion='gini',
                                   random_state=30,
                                   splitter='best',
                                   min_samples_leaf=i)
    clf=clf.fit(Xtrain,Ytrain)
    score=clf.score(Xtest,Ytest)
    test.append(score)
plt.plot(range(1,11),test,color='red',label='min_samples_leaf')
plt.legend()
plt.show()

#min_samples_split从2开始
test=[]
for i in range(2,30):
    clf=tree.DecisionTreeClassifier(max_depth=3,
                                   criterion='gini',
                                   random_state=30,
                                   splitter='best',
                                   min_samples_leaf=1
                                   ,min_samples_split=i)
    clf=clf.fit(Xtrain,Ytrain)
    score=clf.score(Xtest,Ytest)
    test.append(score)
plt.plot(range(2,30),test,color='red',label='min_samples_split')
plt.legend()
plt.show()

dot_data=tree.export_graphviz(clf
                             ,feature_names=feature_name
                             ,class_names=['qin','sher','belmore']
                             ,filled=True
                             ,rounded=True)
graph=graphviz.Source(dot_data)
graph


test=[]
for i in range(1,14):
    clf=tree.DecisionTreeClassifier(max_depth=3,
                                   criterion='gini',
                                   random_state=30,
                                   splitter='best',
                                   min_samples_leaf=1
                                   ,min_samples_split=2
                                   ,max_features=i)
    clf=clf.fit(Xtrain,Ytrain)
    score=clf.score(Xtest,Ytest)
    test.append(score)
plt.plot(range(1,14),test,color='red',label='max_features')
plt.legend()
plt.show()

clf=tree.DecisionTreeClassifier(max_depth=3,
                                   criterion='gini',
                                   random_state=30,
                                   splitter='best',
                                   min_samples_leaf=1
                                   ,min_samples_split=2
                                   ,max_features=13)
clf=clf.fit(Xtrain,Ytrain)
score=clf.score(Xtest,Ytest)
score

clf.apply(Xtest) #返回测试样本所在叶子索引

clf.predict(Xtest)

Ytest.shape  #一维

reshape=Ytest.reshape(-1,1)  #二维
reshape.shape

